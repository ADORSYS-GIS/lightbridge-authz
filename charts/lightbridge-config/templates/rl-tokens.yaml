apiVersion: gateway.envoyproxy.io/v1alpha1
kind: BackendTrafficPolicy
metadata:
  name: {{ include "common.names.fullname" $ }}-rl-tokens
  namespace: {{ include "common.names.namespace" $ }}
spec:
  targetRefs:
    - group: gateway.networking.k8s.io
      kind: HTTPRoute
      name: {{ include "common.names.fullname" $ }}
  rateLimit:
    type: Global
    global:
      rules:
      {{- range $tierName, $_ := .Values.tiers }}
        {{- range $i, $model := $.Values.models }}
          {{- if eq (include "allowed" (dict "tier" $tierName "model" $model.name "context" $)) "true" }}
        # minute window
        - clientSelectors:
            - headers: [{ name: {{ include "H.user" $ }}, type: Distinct }]
            - headers: [{ name: {{ include "H.tier" $ }}, value: {{ $tierName }} }]
            - headers: [{ name: {{ include "H.model" $ }}, value: {{ $model.name }} }]
          limit:
            requests: {{ include "limit.get" (dict "tier" $tierName "kind" "tokensPerMin" "model" $model.name "context" $) | int }}
            unit: Minute
          cost:
            request:
              from: Number
              number: 0      # Set to 0 so only token usage counts
            response:
              from: Metadata
              metadata:
                namespace: io.envoy.ai_gateway
                key: llm_total_token    # Uses total tokens from the response
        # monthly window
        - clientSelectors:
            - headers: [{ name: {{ include "H.user" $ }}, type: Distinct }]
            - headers: [{ name: {{ include "H.tier" $ }}, value: {{ $tierName }} }]
            - headers: [{ name: {{ include "H.model" $ }}, value: {{ $model.name }} }]
          limit:
            requests: {{ include "limit.get" (dict "tier" $tierName "kind" "tokensPerMonth" "model" $model.name "context" $) }}
            unit: Month
          cost:
            request:
              from: Number
              number: 0      # Set to 0 so only token usage counts
            response:
              from: Metadata
              metadata:
                namespace: io.envoy.ai_gateway
                key: llm_total_token    # Uses total tokens from the response
          {{- end }}
        {{- end }}
      {{- end }}
